{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据预处理（预估耗时：1-2小时）\n",
    "任务：\n",
    "解析 train.txt 和 test_without_label.txt 文件，建立文本和图像的配对数据集。\n",
    "对文本数据进行清洗（如去除特殊字符、分词）并转为向量表示（如TF-IDF、Word2Vec或BERT嵌入）。\n",
    "对图像数据进行标准化和特征提取（如通过预训练模型 ResNet/VGG 提取特征）。\n",
    "划分训练集、验证集（建议 8:2 比例）。\n",
    "输出：\n",
    "预处理后的训练集和验证集。\n",
    "可视化部分数据的分布（情感类别比例）。\n",
    "\n",
    "文本预处理：清洗、分词，使用BERT或Word2Vec提取特征。\n",
    "图像预处理：通过ResNet或VGG提取图像特征。\n",
    "数据划分：将训练集划分为训练和验证集（8:2）。\n",
    "可视化：展示情感类别的分布。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How I feel today #legday #jelly #aching #gym \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 读取训练集标签\n",
    "train_labels = pd.read_csv('E:/Learning_material/junior/AI/5_FinalLab/dataset/train.txt', sep=' ', header=None, names=['guid', 'label'])\n",
    "\n",
    "# 读取测试集，标签为空\n",
    "test_guids = pd.read_csv('E:/Learning_material/junior/AI/5_FinalLab/dataset/test_without_label.txt', header=None, names=['guid', 'label'])\n",
    "\n",
    "# 定义加载图像的函数\n",
    "def load_image(guid):\n",
    "    image_path = os.path.join('E:/Learning_material/junior/AI/5_FinalLab/dataset/data', f\"{guid}.jpg\")\n",
    "    return Image.open(image_path)\n",
    "\n",
    "def load_text(guid):\n",
    "    text_path = os.path.join('E:/Learning_material/junior/AI/5_FinalLab/dataset/data', f\"{guid}.txt\")\n",
    "    with open(text_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "# load_image(1)\n",
    "# load_text(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本预处理\n",
    "清洗文本数据，去除特殊字符、分词（如使用 nltk 或 spaCy 库），然后将文本转化为向量表示。你可以使用：\n",
    "TF-IDF：适用于较简单的文本特征提取。\n",
    "Word2Vec/BERT：适用于更加复杂的情感分析任务，能捕捉上下文信息。\n",
    "例如，使用 BERT 嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_text(text):\n",
    "    # 对文本进行分词并转化为 BERT 输入\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # 获取 BERT 模型输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # 提取最后一层的隐藏状态并做池化处理\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 图像预处理\n",
    "使用预训练模型（如 ResNet 或 VGG）提取图像特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Learning_material\\junior\\AI\\5_FinalLab\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\Learning_material\\junior\\AI\\5_FinalLab\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 预处理图像\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加载预训练的ResNet50模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 特征提取函数\n",
    "def extract_image_features(image):\n",
    "    image_tensor = preprocess(image).unsqueeze(0)  # 扩展批量维度\n",
    "    with torch.no_grad():\n",
    "        features = model(image_tensor)\n",
    "    return features.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/Learning_material/junior/AI/5_FinalLab/dataset/data\\\\guid,tag.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 假设你已经加载了文本向量和图像特征\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# X_text = [encode_text(text) for text in train_labels['guid']]  # 用你的数据填充\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_text \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mencode_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mguid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mguid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 通过 guid 获取文本\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# X_image = [extract_image_features(load_image(guid)) for guid in train_labels['guid']]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_image \u001b[38;5;241m=\u001b[39m [extract_image_features(load_image(guid)) \u001b[38;5;28;01mfor\u001b[39;00m guid \u001b[38;5;129;01min\u001b[39;00m train_labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 假设你已经加载了文本向量和图像特征\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# X_text = [encode_text(text) for text in train_labels['guid']]  # 用你的数据填充\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_text \u001b[38;5;241m=\u001b[39m [encode_text(\u001b[43mload_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguid\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m guid \u001b[38;5;129;01min\u001b[39;00m train_labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguid\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \u001b[38;5;66;03m# 通过 guid 获取文本\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# X_image = [extract_image_features(load_image(guid)) for guid in train_labels['guid']]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_image \u001b[38;5;241m=\u001b[39m [extract_image_features(load_image(guid)) \u001b[38;5;28;01mfor\u001b[39;00m guid \u001b[38;5;129;01min\u001b[39;00m train_labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m, in \u001b[0;36mload_text\u001b[1;34m(guid)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_text\u001b[39m(guid):\n\u001b[0;32m     17\u001b[0m     text_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Learning_material/junior/AI/5_FinalLab/dataset/data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mguid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32me:\\Learning_material\\junior\\AI\\5_FinalLab\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/Learning_material/junior/AI/5_FinalLab/dataset/data\\\\guid,tag.txt'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设你已经加载了文本向量和图像特征\n",
    "# X_text = [encode_text(text) for text in train_labels['guid']]  # 用你的数据填充\n",
    "X_text = [encode_text(load_text(guid)) for guid in train_labels['guid']]  # 通过 guid 获取文本\n",
    "# X_image = [extract_image_features(load_image(guid)) for guid in train_labels['guid']]\n",
    "X_image = [extract_image_features(load_image(guid)) for guid in train_labels['guid']]\n",
    "y = train_labels['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(list(zip(X_text, X_image)), y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Learning_material\\junior\\AI\\5_FinalLab\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\Learning_material\\junior\\AI\\5_FinalLab\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0xac in position 75: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 53\u001b[0m\n\u001b[0;32m     49\u001b[0m X_image \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m guid \u001b[38;5;129;01min\u001b[39;00m train_labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguid\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# 先加载文本\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mload_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text:  \u001b[38;5;66;03m# 确保文本数据存在\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         X_text\u001b[38;5;241m.\u001b[39mappend(encode_text(text))  \u001b[38;5;66;03m# 通过encode_text处理文本\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 41\u001b[0m, in \u001b[0;36mload_text\u001b[1;34m(guid)\u001b[0m\n\u001b[0;32m     39\u001b[0m text_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Learning_material/junior/AI/5_FinalLab/dataset/data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mguid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(text_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0xac in position 75: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# BERT模型准备（用于文本处理）\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # BERT模型输入文本并获取输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # 提取最后一层的隐藏状态并做池化处理\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "# ResNet模型准备（用于图像处理）\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()\n",
    "\n",
    "def extract_image_features(image):\n",
    "    image_tensor = preprocess(image).unsqueeze(0)  # 添加批量维度\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(image_tensor)\n",
    "    return features.squeeze().detach().numpy()\n",
    "\n",
    "# 加载文本和图像文件的路径\n",
    "def load_text(guid):\n",
    "    text_path = os.path.join('E:/Learning_material/junior/AI/5_FinalLab/dataset/data', f\"{guid}.txt\")\n",
    "    with open(text_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "def load_image(guid):\n",
    "    image_path = os.path.join('E:/Learning_material/junior/AI/5_FinalLab/dataset/data', f\"{guid}.jpg\")\n",
    "    return Image.open(image_path)\n",
    "\n",
    "# 假设train_labels已经正确加载，train_labels['guid']是文件名的基础部分\n",
    "X_text = []\n",
    "X_image = []\n",
    "\n",
    "for guid in train_labels['guid']:\n",
    "    # 先加载文本\n",
    "    text = load_text(guid)\n",
    "    if text:  # 确保文本数据存在\n",
    "        X_text.append(encode_text(text))  # 通过encode_text处理文本\n",
    "    # 然后加载图像\n",
    "    image = load_image(guid)\n",
    "    X_image.append(extract_image_features(image))  # 通过extract_image_features提取图像特征\n",
    "\n",
    "y = train_labels['label'].values  # 获取标签列\n",
    "\n",
    "# 划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(list(zip(X_text, X_image)), y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "train_labels['label'].value_counts().plot(kind='bar', color=['green', 'blue', 'red'])\n",
    "plt.title('Emotion Label Distribution')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
